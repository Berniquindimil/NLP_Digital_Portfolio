{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next text, perform the following actions\n",
    "text = \"The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.\"\n",
    "\n",
    "# (1 point) 1 - Use NLTK to split the sentences \n",
    "\n",
    "# (2 points) 2 - Convert with regex the acronym U.S.A. to USA, the number 1.9m to 190 centimeters or any other number of a height like that (e.g. 1.75m to 175 centimeters), and \"$5.5 billion\" to five point five billion. \n",
    "\n",
    "# (1 point) 3 - Convert to lowercase except the proper nouns that must keep the original case. For the multiword proper names convert them to an unique word joining the two word with underscoere (Juan Fern치ndez -> Juan_Fern치ndez).\n",
    "\n",
    "# (1 point) 4 - Tokenize the text (use the tool you prefer). \n",
    "\n",
    "# (1 point) 5 - Remove the stopwords (use the tool you prefer). \n",
    "\n",
    "# (1 point) 6 - Create bigrams with pure python.\n",
    "\n",
    "# (2 point) 7 - Create a language model that predict the next word using bigrams. Please explain in the code how you made the calculations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The president of the U.S.A., Donald Trump, is 1.9m high and 78 years old.', 'Forbes Magazine has assessed his wealth, currently estimating it at $5.5 billion as of mid-February 2025.']\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 1 - Use NLTK to split the sentences \n",
    "tokens = nltk.sent_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The president of the USA, Donald Trump, is 19 0 centimeters high and 78 years old. Forbes Magazine has assessed his wealth, currently estimating it at five point five billion as of mid-February 2025.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (2 points) 2 - Convert with regex the acronym U.S.A. to USA, the number 1.9m to 190 centimeters or any other number of a height like that (e.g. 1.75m to 175 centimeters), and \"$5.5 billion\" to five point five billion. \n",
    "result = re.sub(r'U.S.A.', r'USA',text)\n",
    "result = re.sub(r'(\\d)+\\.(\\d)+m', r'\\1\\2 0 centimeters', result)\n",
    "result = re.sub(r'\\$5.5 billion', r'five point five billion',result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the president of the U.S.A. , Donald_Trump , is 1.9 m high and 78 years old . Forbes_Magazine has assessed his wealth , currently estimating it at $ 5.5 billion as of mid - February 2025 .'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1 point) 3 - Convert to lowercase except the proper nouns that must keep the original case. For the multiword proper names convert them to an unique word joining the two word with underscoere (Juan Fern치ndez -> Juan_Fern치ndez).\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "processed_words = []\n",
    "\n",
    "# the library identify the pronouns being\n",
    "for token in doc:\n",
    "    if token.pos_ == \"PROPN\" and not token.is_space:\n",
    "        processed_words.append(token.text)\n",
    "        if last_token == \"PROPN\" and not last_token.is_space:\n",
    "            processed_words.remove(last_token)\n",
    "            processed_words.append(last_token + \"_\" + token)\n",
    "    elif token.is_space:\n",
    "        processed_words.append(token.text)\n",
    "    else:\n",
    "        processed_words.append(token.text.lower())\n",
    "    last_token = token\n",
    "\n",
    "result = \" \".join(processed_words)\n",
    "\n",
    "\n",
    "result = re.sub(r'\\b(Donald) (Trump)\\b', r'\\1_\\2', result)\n",
    "result = re.sub(r'\\b(Forbes) (Magazine)\\b', r'\\1_\\2', result)\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'president', 'of', 'the', 'U.S.A.', ',', 'Donald', 'Trump', ',', 'is', '1.9m', 'high', 'and', '78', 'years', 'old', '.', 'Forbes', 'Magazine', 'has', 'assessed', 'his', 'wealth', ',', 'currently', 'estimating', 'it', 'at', '$', '5.5', 'billion', 'as', 'of', 'mid-February', '2025', '.']\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 4 - Tokenize the text (use the tool you prefer). \n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['president', 'U.S.A.', ',', 'Donald', 'Trump', ',', '1.9m', 'high', '78', 'years', 'old', '.', 'Forbes', 'Magazine', 'assessed', 'wealth', ',', 'currently', 'estimating', '$', '5.5', 'billion', 'mid-February', '2025', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bernardoquindimil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 5 - Remove the stopwords (use the tool you prefer).\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    " \n",
    "#with no lower case conversion\n",
    "filtered_sentence = []\n",
    " \n",
    "for w in tokens:\n",
    "    if w.lower() not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    " \n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'president'], ['president', 'of'], ['of', 'the'], ['the', 'U.S.A.,'], ['U.S.A.,', 'Donald'], ['Donald', 'Trump,'], ['Trump,', 'is'], ['is', '1.9m'], ['1.9m', 'high'], ['high', 'and'], ['and', '78'], ['78', 'years'], ['years', 'old.'], ['old.', 'Forbes'], ['Forbes', 'Magazine'], ['Magazine', 'has'], ['has', 'assessed'], ['assessed', 'his'], ['his', 'wealth,'], ['wealth,', 'currently'], ['currently', 'estimating'], ['estimating', 'it'], ['it', 'at'], ['at', '$5.5'], ['$5.5', 'billion'], ['billion', 'as'], ['as', 'of'], ['of', 'mid-February'], ['mid-February', '2025.']]\n"
     ]
    }
   ],
   "source": [
    "# (1 point) 6 - Create bigrams with pure python.\n",
    "words = text.split()\n",
    "\n",
    "bigrams = []\n",
    "for i in range(len(words)-1):\n",
    "    bigrams.append([words[i], words[i+1]])\n",
    "\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2 point) 7 - Create a language model that predict the next word using bigrams. Please explain in the code how you made the calculations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
